{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3장 시카고 샌드위치 맛집 분석\n",
    "\n",
    "## 3-1 웹 데이터를 가져오는 Beautiful Soup 익히기\n",
    "\n",
    "- Beautiful Soup이란?\n",
    "    - 웹에서 웹 페이지의 내용을 가져옴.\n",
    "    - 웹 데이터 크롤링 또는 스크래핑 할 때 사용\n",
    "        - 웹 크롤링(Web Crawling)\n",
    "            - 검색엔진에서 사용되는 bot과 같이 자동으로 웹처리됨\n",
    "            - 다운로드한 사이트를 index하여 사용자가 빠르게 원하는 것을 검색할 수 있도록 해줌 -> ex) 구글\n",
    "        - 웹 스크래핑(Web Scraping)\n",
    "            - 웹 사이트에서 원하는 데이터를 추출함\n",
    "            - 추출한 데이터를 원하는 형식으로 가공함\n",
    "            - 웹 크롤링도 웹 스크래핑의 방법 중 하나\n",
    "    - HTML과 XML 파일에서 데이터를 읽어내는 파이썬 라이브러리\n",
    "        - XML(eXtensible Markup Language) : 데이터를 저장하고 전달하기 위해 디자인된 언어\n",
    "        - HTML(Hyper Text Markup Language) : 데이터를 웹 상에 표현하기 위한 목적으로 사용되는 언어\n",
    "    - Parser 트리를 검색, 수정하는데 간편하고 사용자가 만든 parcer와 함께 사용하기 쉽다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beautiful Soup 설치 확인\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Very Simple HTML Code by PinkWink\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <div>\n",
      "   <p class=\"inner-text first-item\" id=\"first\">\n",
      "    Happy PinkWink.\n",
      "    <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">\n",
      "     PinkWink\n",
      "    </a>\n",
      "   </p>\n",
      "   <p class=\"inner-text second-item\">\n",
      "    Happy Data Science.\n",
      "    <a href=\"https://www.python.org\" id=\"py-link\">\n",
      "     Python\n",
      "    </a>\n",
      "   </p>\n",
      "  </div>\n",
      "  <p class=\"outer-text first-item\" id=\"second\">\n",
      "   <b>\n",
      "    Data Science is funny.\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"outer-text\">\n",
      "   <b>\n",
      "    All I need is Love.\n",
      "   </b>\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 03. test_first.html 파일을 읽어오기\n",
    "page = open('data/03. test_first.html','r').read()\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "# html.parse : HTML 문법 규칙에 따른 문자열을 해당 문법을 바탕으로\n",
    "#              단어의 의미나 구조를 분석하는 것을 의미\n",
    "# html.parser : HTML Parse를 행하는 프로그램을 말함\n",
    "\n",
    "# prettify()\n",
    "# 1. 읽은 html 페이지의 내용을 전체 다 보고 싶을 때 사용하는 함수, 들여쓰기 지원\n",
    "# 2. BeautifulSoup에서 파싱 처리한 parser tree를 유니코드 형태로 리턴하는 함수\n",
    "\n",
    "print(soup.prettify()) # soup 변수 안에 들어있는 모든 내용 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['html',\n",
       " '\\n',\n",
       " <html>\n",
       " <head>\n",
       " <title>Very Simple HTML Code by PinkWink</title>\n",
       " </head>\n",
       " <body>\n",
       " <div>\n",
       " <p class=\"inner-text first-item\" id=\"first\">\n",
       "                 Happy PinkWink.\n",
       "                 <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
       " </p>\n",
       " <p class=\"inner-text second-item\">\n",
       "                 Happy Data Science.\n",
       "                 <a href=\"https://www.python.org\" id=\"py-link\">Python</a>\n",
       " </p>\n",
       " </div>\n",
       " <p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 Data Science is funny.\n",
       "             </b>\n",
       " </p>\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 All I need is Love.\n",
       "             </b>\n",
       " </p>\n",
       " </body>\n",
       " </html>,\n",
       " '\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# soup은 문서 전체를 저장한 변수, 그 안에서 html 태그에 접속하려면 children 이라는 속성을 사용\n",
    "# children : 한 단계 아래에 있는 태그를 보기 위한 함수\n",
    "\n",
    "list(soup.children) # soup 안에 있는 html 태그를 보고싶을 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>Very Simple HTML Code by PinkWink</title>\n",
       "</head>\n",
       "<body>\n",
       "<div>\n",
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                Happy PinkWink.\n",
       "                <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
       "</p>\n",
       "<p class=\"inner-text second-item\">\n",
       "                Happy Data Science.\n",
       "                <a href=\"https://www.python.org\" id=\"py-link\">Python</a>\n",
       "</p>\n",
       "</div>\n",
       "<p class=\"outer-text first-item\" id=\"second\">\n",
       "<b>\n",
       "                Data Science is funny.\n",
       "            </b>\n",
       "</p>\n",
       "<p class=\"outer-text\">\n",
       "<b>\n",
       "                All I need is Love.\n",
       "            </b>\n",
       "</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# soup의 내용 안에 있는 html 태그에 접근하기 위한 코드\n",
    "# html = list(soup.children)[0]    --> html\n",
    "# html = list(soup.children)[1]    --> \\n\n",
    "# html = list(soup.children)[2]    --> html 코드\n",
    "\n",
    "html = list(soup.children)[2]  # html 코드 출력\n",
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " <head>\n",
       " <title>Very Simple HTML Code by PinkWink</title>\n",
       " </head>,\n",
       " '\\n',\n",
       " <body>\n",
       " <div>\n",
       " <p class=\"inner-text first-item\" id=\"first\">\n",
       "                 Happy PinkWink.\n",
       "                 <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
       " </p>\n",
       " <p class=\"inner-text second-item\">\n",
       "                 Happy Data Science.\n",
       "                 <a href=\"https://www.python.org\" id=\"py-link\">Python</a>\n",
       " </p>\n",
       " </div>\n",
       " <p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 Data Science is funny.\n",
       "             </b>\n",
       " </p>\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 All I need is Love.\n",
       "             </b>\n",
       " </p>\n",
       " </body>,\n",
       " '\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# html 태그 밑에 있는 모든 태그들이 html.children에 해당 \n",
    "\n",
    "list(html.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러분들이 htmlex = list(html.children)[0]\n",
    "\n",
    "# 스스로 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body>\n",
       "<div>\n",
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                Happy PinkWink.\n",
       "                <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
       "</p>\n",
       "<p class=\"inner-text second-item\">\n",
       "                Happy Data Science.\n",
       "                <a href=\"https://www.python.org\" id=\"py-link\">Python</a>\n",
       "</p>\n",
       "</div>\n",
       "<p class=\"outer-text first-item\" id=\"second\">\n",
       "<b>\n",
       "                Data Science is funny.\n",
       "            </b>\n",
       "</p>\n",
       "<p class=\"outer-text\">\n",
       "<b>\n",
       "                All I need is Love.\n",
       "            </b>\n",
       "</p>\n",
       "</body>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 본문이 나오는 body부분만 추출\n",
    "\n",
    "body = list(html.children)[3]\n",
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body>\n",
       "<div>\n",
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                Happy PinkWink.\n",
       "                <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
       "</p>\n",
       "<p class=\"inner-text second-item\">\n",
       "                Happy Data Science.\n",
       "                <a href=\"https://www.python.org\" id=\"py-link\">Python</a>\n",
       "</p>\n",
       "</div>\n",
       "<p class=\"outer-text first-item\" id=\"second\">\n",
       "<b>\n",
       "                Data Science is funny.\n",
       "            </b>\n",
       "</p>\n",
       "<p class=\"outer-text\">\n",
       "<b>\n",
       "                All I need is Love.\n",
       "            </b>\n",
       "</p>\n",
       "</body>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# soup.body : 태그를 바로 입력하여 원하는 태그만 추출\n",
    "\n",
    "soup.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " <div>\n",
       " <p class=\"inner-text first-item\" id=\"first\">\n",
       "                 Happy PinkWink.\n",
       "                 <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
       " </p>\n",
       " <p class=\"inner-text second-item\">\n",
       "                 Happy Data Science.\n",
       "                 <a href=\"https://www.python.org\" id=\"py-link\">Python</a>\n",
       " </p>\n",
       " </div>,\n",
       " '\\n',\n",
       " <p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 Data Science is funny.\n",
       "             </b>\n",
       " </p>,\n",
       " '\\n',\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 All I need is Love.\n",
       "             </b>\n",
       " </p>,\n",
       " '\\n']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# body 태그 아래에 있는 태그를 추출\n",
    "\n",
    "list(body.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 Happy PinkWink.\n",
       "                 <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
       " </p>,\n",
       " <p class=\"inner-text second-item\">\n",
       "                 Happy Data Science.\n",
       "                 <a href=\"https://www.python.org\" id=\"py-link\">Python</a>\n",
       " </p>,\n",
       " <p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 Data Science is funny.\n",
       "             </b>\n",
       " </p>,\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 All I need is Love.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find_all : p 태그를 가진 모든 태그를 찾아낸다.\n",
    "\n",
    "soup.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                Happy PinkWink.\n",
       "                <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
       "</p>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find : p 태그를 가진 태그를 찾아낸다.(맨 처음거만 찾아낸다.)\n",
    "\n",
    "soup.find('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 Data Science is funny.\n",
       "             </b>\n",
       " </p>,\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 All I need is Love.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p 태그들 중에서 class가 'outer-text'인 것만 찾아낸다.\n",
    "\n",
    "soup.find_all('p', class_ = 'outer-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 Data Science is funny.\n",
       "             </b>\n",
       " </p>,\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 All I need is Love.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class가 'outer-text'인 것만 찾아낸다.\n",
    "\n",
    "soup.find_all(class_='outer-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 Happy PinkWink.\n",
       "                 <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
       " </p>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id가 'first'인 것만 찾아낸다.\n",
    "\n",
    "soup.find_all(id='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                Happy PinkWink.\n",
       "                <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
       "</p>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가장 처음 p 태그만 찾아낸다.\n",
    "\n",
    "soup.find('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['html',\n",
       " '\\n',\n",
       " <html>\n",
       " <head>\n",
       " <title>Very Simple HTML Code by PinkWink</title>\n",
       " </head>\n",
       " <body>\n",
       " <div>\n",
       " <p class=\"inner-text first-item\" id=\"first\">\n",
       "                 Happy PinkWink.\n",
       "                 <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
       " </p>\n",
       " <p class=\"inner-text second-item\">\n",
       "                 Happy Data Science.\n",
       "                 <a href=\"https://www.python.org\" id=\"py-link\">Python</a>\n",
       " </p>\n",
       " </div>\n",
       " <p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 Data Science is funny.\n",
       "             </b>\n",
       " </p>\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 All I need is Love.\n",
       "             </b>\n",
       " </p>\n",
       " </body>\n",
       " </html>,\n",
       " '\\n']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(soup.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head>\n",
       "<title>Very Simple HTML Code by PinkWink</title>\n",
       "</head>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# head 부부만 추출\n",
    "\n",
    "soup.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# head 바로 옆에 있는 내용을 추출\n",
    "soup.head.next_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body>\n",
       "<div>\n",
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                Happy PinkWink.\n",
       "                <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
       "</p>\n",
       "<p class=\"inner-text second-item\">\n",
       "                Happy Data Science.\n",
       "                <a href=\"https://www.python.org\" id=\"py-link\">Python</a>\n",
       "</p>\n",
       "</div>\n",
       "<p class=\"outer-text first-item\" id=\"second\">\n",
       "<b>\n",
       "                Data Science is funny.\n",
       "            </b>\n",
       "</p>\n",
       "<p class=\"outer-text\">\n",
       "<b>\n",
       "                All I need is Love.\n",
       "            </b>\n",
       "</p>\n",
       "</body>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# head 옆 옆 부분에 있는 내용 추출 (body)\n",
    "soup.head.next_sibling.next_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                Happy PinkWink.\n",
       "                <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
       "</p>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find함수를 쓰지 않아도 body.p라고 입력하여도 같은 ouput을 보여준다\n",
    "body.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"inner-text second-item\">\n",
       "                Happy Data Science.\n",
       "                <a href=\"https://www.python.org\" id=\"py-link\">Python</a>\n",
       "</p>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p태그의 다음 다음 p태그를 보여준다.\n",
    "# body.p.next_sibling을 입력하면 '\\n'이 출력된다.\n",
    "\n",
    "body.p.next_sibling.next_sibling\n",
    "# body.p.next_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                Happy PinkWink.\n",
      "                PinkWink\n",
      "\n",
      "\n",
      "                Happy Data Science.\n",
      "                Python\n",
      "\n",
      "\n",
      "\n",
      "                Data Science is funny.\n",
      "            \n",
      "\n",
      "\n",
      "\n",
      "                All I need is Love.\n",
      "            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 찾아야 할 태그를 알고 있다면, find() 또는 find_all() 함수 사용\n",
    "# 모든 p태그를 찾아서 \n",
    "\n",
    "for each_tag in soup.find_all('p') :\n",
    "    print(each_tag.get_text())         # get_text() : p 태그 안에 든 text만을 출력함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n                Happy PinkWink.\\n                PinkWink\\n\\n\\n                Happy Data Science.\\n                Python\\n\\n\\n\\n\\n                Data Science is funny.\\n            \\n\\n\\n\\n                All I need is Love.\\n            \\n\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# body 부분에 있는 text들을 출력해낸다.\n",
    "# body.get_text()를 하게 되면 태그가 있던 자리는 줄바꿈(\\n)이 표시되고 전체 리스트를 보여줌\n",
    "\n",
    "body.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>,\n",
       " <a href=\"https://www.python.org\" id=\"py-link\">Python</a>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클릭 가능한 링크를 의미하는 a태그를 전부 찾아낸다.\n",
    "\n",
    "links = soup.find_all('a')\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2 크롬 개발자 도구를 이용해서 원하는 태그 찾기\n",
    "\n",
    "- chrome 맞춤 설정 및 제어 -> 클릭 -> 도구 더보기 -> 개발자 도구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url을 요청하여 오픈하는 패키지\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url을 입력\n",
    "url = 'https://finance.naver.com/marketindex/'\n",
    "# 네이버 홈페이지 -> 증권 -> 시장지표\n",
    "\n",
    "# url 오픈\n",
    "page = urlopen(url)\n",
    "\n",
    "# BS를 사용하여 html을 읽어온다.\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "# prettify()를 사용하여 html을 보기 좋게 정렬\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.find_all('span','value')\n",
    "soup.find_all('span',class_ = 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('span',class_ = 'value')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0번째 span 태그에 class = value에 들어있는 text를 추출\n",
    "\n",
    "soup.find_all('span','value')[0].string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('span','value')[1].string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('span','value')[2].string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3 실전 : 시카고 샌드위치 맛집 소개 사이트에 접근하기\n",
    "- 웹 스크래핑 목표 : 가게 이름, 가게 메인 메뉴, 각 가게 소개페이지를 정리하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# 기본이 되는 url 설정\n",
    "url_base = 'https://www.chicagomag.com'\n",
    "\n",
    "# 원하는 페이지에 가기 위한 나머지 주고\n",
    "url_sub = '/Chicago-Magazine/November-2012/Best-Sandwiches-Chicago/'\n",
    "\n",
    "# 두 url을 합쳐준다\n",
    "url = url_base + url_sub\n",
    "\n",
    "# url 오픈\n",
    "html = urlopen(url)\n",
    "\n",
    "# BS를 이용하여 html을 읽어온다.\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# div 태그 중 class이름이 sammy인 것을 모두 찾는다.\n",
    "print(soup.find_all('div','sammy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(soup.find_all('div','sammy')) # 맛집 50개 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.find_all('div','sammy')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-4 접근한 웹 페이지에서 원하는 데이터 추출하고 정리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0번째 div태그의 class = sammy를 찾아낸다.\n",
    "tmp_one = soup.find_all('div','sammy')[0]\n",
    "\n",
    "# tmp_one의 타입을 확인\n",
    "type(tmp_one)\n",
    "\n",
    "# bs4.element.Tag  --> 그 변수에서 다시 태그로 찾는 find, find_all을 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_one에 있는 태그들 중에 class = 'sammyRank'라는 것을 찾는다.\n",
    "\n",
    "tmp_one.find(class_ = 'sammyRank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_one에 있는 태그들 중에 class = 'sammyRank'의 text를 추출한다.\n",
    "\n",
    "tmp_one.find(class_ = 'sammyRank').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_one에 있는 태그들 중에 class = 'sammyListing'의 text를 추출한다.\n",
    "# sammyListing을 얻으면 메뉴 이름과 가게 이름이 같의 나온다.\n",
    "\n",
    "tmp_one.find(class_ = 'sammyListing').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_one에 있는 태그들 중에 a 태그의 href를 추출한다.\n",
    "\n",
    "tmp_one.find('a')['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규식을 위해서 re를 import\n",
    "# 파이썬에서 정규표현식을 사용하기 위해 Regex(Regular Expression)를 위한 모듈 re를 사용\n",
    "\n",
    "import re\n",
    "\n",
    "# tmp_one에 있는 태그들 중에 class = 'sammyListing'의 text를 추출한다.\n",
    "tmp_string = tmp_one.find(class_ = 'sammyListing').get_text()\n",
    "\n",
    "# '\\n'이나 '\\r'이 있으면 그것들을 기준으로 나눈다.\n",
    "re.split(('\\n|\\r\\n'), tmp_string)\n",
    "\n",
    "# 위에서 나눈 것을 0, 1번째를 출력\n",
    "print(re.split(('\\n|\\r\\n'), tmp_string)[0])\n",
    "print(re.split(('\\n|\\r\\n'), tmp_string)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urljoin\n",
    "\n",
    "# 데이터를 담을 list를 만든다.\n",
    "rank = []\n",
    "main_menu = []\n",
    "cafe_name = []\n",
    "url_add = []\n",
    "\n",
    "# div태그의 class = 'sammy'를 가진 것을 전부 찾아낸다.\n",
    "list_soup = soup.find_all('div','sammy')\n",
    "\n",
    "# 전부 찾아낸 div태그들을 for문의 범위에 넣고 \n",
    "for item in list_soup :\n",
    "    # class = 'sammyRank'에 있는 text를 추출하고, rank 리스트에 추가\n",
    "    rank.append(item.find(class_ = 'sammyRank').get_text())\n",
    "                \n",
    "    # class = 'sammyListing'에 있는 text를 추출\n",
    "    tmp_string = item.find(class_ = 'sammyListing').get_text()\n",
    "    \n",
    "    # '\\n'이나 '\\r'을 기준으로 text를 나누고 0번째는 main_menu에 추가하고\n",
    "    # 1번째는 cafe_name에 추가한다.\n",
    "    main_menu.append(re.split(('\\n|\\r\\n'), tmp_string)[0])\n",
    "    cafe_name.append(re.split(('\\n|\\r\\n'), tmp_string)[1])\n",
    "    \n",
    "    # 맨 처음 기본이 되는 url에 a 태그에 있는 href를 추가한다.\n",
    "    url_add.append(urljoin(url_base, item.find('a')['href']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 확인 작업\n",
    "\n",
    "rank[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_menu[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cafe_name[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_add[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rank), len(main_menu), len(cafe_name), len(url_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 프레임의 각 컬럼의 이름을 'Rank', 'Menu', 'Cafe', 'URL'로 지정하고\n",
    "# value는 위에서 찾은 내용들을 넣어준다.\n",
    "\n",
    "data = {'Rank':rank, 'Menu':main_menu,'Cafe':cafe_name, 'URL':url_add}\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼의 순서를 변경해준다.\n",
    "\n",
    "df = pd.DataFrame(data, columns = ['Cafe', 'Menu', 'Rank', 'URL'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '03. best_sandwiches_list_chicago.csv'로 저장\n",
    "\n",
    "df.to_csv('data/03. best_sandwiches_list_chicago.csv', sep=',',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-5 다수의 웹 페이지에 자동으로 접근해서 원하는 정보 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장한 csv를 읽어온다.\n",
    "\n",
    "df = pd.read_csv('data/03. best_sandwiches_list_chicago.csv', index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['URL'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL 컬럼에 0번째 있는 url을 출력한다.\n",
    "df['URL'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL 컬럼에 0번째 있는 url을 오픈\n",
    "\n",
    "html = urlopen(df['URL'][0])\n",
    "soup_tmp = BeautifulSoup(html, 'html.parser')\n",
    "soup_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫번째 p 태그의 class = 'addy'를 찾는다.\n",
    "print(soup_tmp.find('p','addy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫번째 p 태그의 class = 'addy'를 찾고 text를 추출\n",
    "price_tmp = soup_tmp.find('p','addy').get_text()\n",
    "price_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 띄어쓰기를 기준으로 나눈다.\n",
    "price_tmp.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0번째 값을 출력\n",
    "price_tmp.split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0번째 값에서 마지막 글자를 제거\n",
    "price_tmp.split()[0][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1번째부터 뒤에서 2번째 값까지 출력 : 주소를 다시 합침\n",
    "' '.join(price_tmp.split()[1:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 넣을 데이터의 리스트를 만든다.\n",
    "price = []\n",
    "address = []\n",
    "\n",
    "# 0번째부터 2번째까지 값을 모두 출력한다.\n",
    "for n in df.index[:3] :\n",
    "    # url을 0, 1, 2순으로 연다\n",
    "    html = urlopen(df['URL'][n])\n",
    "    soup_tmp = BeautifulSoup(html,'lxml')\n",
    "    \n",
    "    # p 태스의 class = 'addy'에 있는 text를 추출\n",
    "    gettings = soup_tmp.find('p','addy').get_text()\n",
    "    \n",
    "    price.append(gettings.split()[0][:-1])\n",
    "    address.append(' '.join(gettings.split()[1:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제대로 되는지 확인\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주소 확인\n",
    "address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-6 주피터 노트북에서 상태 진행바를 쉽게 만들어주는 tqdm 모듈\n",
    "\n",
    "- 아마콘다 네이게이터에서 tqdm 모듈 설치 여부 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-7 상태 진행바까지 적용하고 다시 샌드위치 페이지 50개에 접근하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력화면에 진행상태를 알려주는 패키지\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "price = []\n",
    "address = []\n",
    "\n",
    "# df.index는 50개, 그러므로 for문이 50번 반복\n",
    "for n in tqdm_notebook(df.index) :\n",
    "    # url도 총 50개가 오픈\n",
    "    html = urlopen(df['URL'][n])\n",
    "    soup_tmp = BeautifulSoup(html,'lxml')\n",
    "    \n",
    "    # p 태스의 class = 'addy'에 있는 text를 추출\n",
    "    gettings = soup_tmp.find('p','addy').get_text()\n",
    "    \n",
    "    price.append(gettings.split()[0][:-1])\n",
    "    address.append(' '.join(gettings.split()[1:-2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-8 50개 웹 페이제에 대한 정보 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(price), len(address), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 프레임에 새로운 컬럼을 추가\n",
    "df['Price'] = price\n",
    "df['Address'] = address\n",
    "\n",
    "# 컬럼 정렬\n",
    "df = df.loc[:,['Rank','Cafe','Menu','Price','Address']]\n",
    "\n",
    "# 데이터 프레임의 인덱스를 'Rank'로 변경\n",
    "df.set_index('Rank', inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv로 저장\n",
    "df.to_csv('data/03. best_sandwiches_list_chicago2.csv', sep=',',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-8 맛집 위치를 지도에 표기하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import pandas as pd\n",
    "import googlemaps\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교재 155pd\n",
    "# 저장한 csv를 읽어오기\n",
    "df = pd.read_csv('data/03. best_sandwiches_list_chicago2.csv', index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmaps_key = 'AIzaSyAWrqxPHQRtjKhGQQUsc6F_t3qh62GTwgY' # 2장에서 획득한 자신의 key를 사용\n",
    "gmaps = googlemaps.Client(key=gmaps_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위도, 경도를 저장할 리스트를 만든다.\n",
    "lat = []\n",
    "lng = []\n",
    "\n",
    "# 인덱스가 50개이기 때문에 for이 50번 반복\n",
    "for n in tqdm_notebook(df.index) :\n",
    "    # 주소에 'Multiple'이 있지 않으면, if문을 실행\n",
    "    if df['Address'][n] != 'Multiple' :\n",
    "        \n",
    "        # 주소에 'Chicago'를 추가해서 주소를 완성시킨다.\n",
    "        target_name = df['Address'][n] + ', ' + 'Chicago'\n",
    "        \n",
    "        # 구글맵에서 geocode부분에 접근\n",
    "        gmaps_output = gmaps.geocode(target_name)\n",
    "        \n",
    "        # 'geometry'부분에 위도, 경도가 있으므로 추출\n",
    "        location_output = gmaps_output[0].get('geometry')\n",
    "        \n",
    "        # 각각의 위도, 경도를 리스트에 추가한다.\n",
    "        lat.append(location_output['location']['lat'])\n",
    "        lng.append(location_output['location']['lng'])\n",
    "        \n",
    "    # 주소에 'Multiple'이 있으면.\n",
    "    else :\n",
    "        # 위도, 경도 리스트에 NaN 추가\n",
    "        lat.append(np.nan)\n",
    "        lng.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lat), len(lng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lat'] = lat\n",
    "df['lng'] = lng\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = folium.Map(location = [df['lat'].mean(), df['lng'].mean()], zoom_start=11)\n",
    "\n",
    "folium.Marker([df['lat'].mean(), df['lng'].mean()], popup='center').add_to(mapping)\n",
    "\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = folium.Map(location = [df['lat'].mean(), df['lng'].mean()], zoom_start=11)\n",
    "\n",
    "for n in df.index :\n",
    "    if df['Address'][n] != 'Multiple' :\n",
    "        folium.Marker([df['lat'][n], df['lng'][n]], popup=df['Cafe'][n]).add_to(mapping)\n",
    "\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
