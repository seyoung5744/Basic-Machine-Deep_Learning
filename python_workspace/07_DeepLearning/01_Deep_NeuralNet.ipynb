{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tutorial-garden",
   "metadata": {},
   "source": [
    "Pytorch에서의 Gradient Descent에 대해서 간단하게 먼저 살펴본다.<br>\n",
    "파이토치를 이용해서 선형회귀 모델을 먼저 만들고,<br>\n",
    "경사하강법으로 학습하는 과정을 코드로 작성해 보면서<br>\n",
    "지금까지 PDF로 이해한 내용을 마무리 해 보겠다.<br>\n",
    "\n",
    "파이토치는 데이터의 기본 단위로 텐서(Tensor)를 사용한다.<br>\n",
    "Tensor는 Numpy에서의 np.array() 함수와 동일하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-inflation",
   "metadata": {},
   "source": [
    "### Torch Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "religious-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # 파이토치 프레임워크 불러온다.\n",
    "import torch.nn as nn\n",
    "import torchvision # 파이토치 내에서도 vision, 이미지 Processing에 특화된 모델\n",
    "import torchvision.transforms as transforms # 데이터 변형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-witch",
   "metadata": {},
   "source": [
    "### I. Forward Propagation\n",
    "### Neural Network(NN) Model Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "resistant-belief",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight  Parameter containing:\n",
      "tensor([[-0.5522,  0.3532,  0.5601],\n",
      "        [-0.5606,  0.1509, -0.4419]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 3) # torch로 랜던 데이터 생성\n",
    "y = torch.randn(10, 2) # torch로 랜던 데이터 생성\n",
    "# 위의 행값 10이 batch size\n",
    "\n",
    "# weight? 3x2\n",
    "linear = nn.Linear(3, 2)\n",
    "\n",
    "# 결과값은 내부적으로 transforms를 해서 나옴.\n",
    "# 그래서 2행 3열로 출력됨.   \n",
    "print('Weight ', linear.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sexual-modification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias  Parameter containing:\n",
      "tensor([0.3177, 0.0319], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# bias? 10x2\n",
    "# static 값이기 때문에 10행 모두 똑같은 2가지 값으로 10줄 나오는 것.\n",
    "print('Bias ', linear.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-question",
   "metadata": {},
   "source": [
    "### 선정의 - loss function, optimization \n",
    "- 무슨 방법을 사용할 지 미리 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "piano-purple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x0000020CF49E2C80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "linear.parameters()\n",
    "학습의 주체를 해킹하고 있는 객체\n",
    "parameters() 학습의 주체를 해킹하는 함수\n",
    "해킹한 다는 의미는 parameters()가 w, b를 갖고 있다는 의미\n",
    "- w, b\n",
    "'''\n",
    "linear.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "immediate-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이렇게 선정의 해두고 이런 방식으로 학습 진행\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "reflected-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델에다가 입력값을 넣고, 모델이 예측한 값을 출력\n",
    "pred = linear(x)\n",
    "\n",
    "# loss - 얼마나 예측을 잘했나 못했나\n",
    "loss = loss_function(pred, y)\n",
    "\n",
    "# 여기까지가 forward propagation의 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "headed-triple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss before step BackPropagation  tensor(1.9875, grad_fn=<MseLossBackward>)\n",
      "Loss before step BackPropagation  1.9875062704086304\n"
     ]
    }
   ],
   "source": [
    "# torch의 데이터 타입은 tensor\n",
    "# tensor(1.9875, grad_fn=<MseLossBackward>)\n",
    "print('Loss before step BackPropagation ', loss) \n",
    "\n",
    "# tensor에 있는 값만 추출하고 싶을 때 ->item()\n",
    "print('Loss before step BackPropagation ', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-institute",
   "metadata": {},
   "source": [
    "### II. Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "compressed-marks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward 하면 책임을 물어서 loss가 낮게 값 조정. 미분 진행\n",
    "# backward만 시켰을 뿐 수정된 값으로 하강을 한 것은 아님.\n",
    "# Loss값에 따른 weight, bias값의 미분한 값만 알아낸 것...아직 학습이 진행된건 아니다...실질적으로 하강안함\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "deadly-island",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL/dW :  tensor([[-1.2079, -0.1326,  0.1025],\n",
      "        [-0.5358,  0.0892, -0.2418]])\n",
      "dL/db :  tensor([1.0982, 0.3864])\n"
     ]
    }
   ],
   "source": [
    "print('dL/dW : ', linear.weight.grad)\n",
    "print('dL/db : ', linear.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "first-sauce",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step() # 이때 위에서 변경된 값으로 하강을 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "moderate-crown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after Step BackPropagation  1.9557676315307617\n"
     ]
    }
   ],
   "source": [
    "# 반복 효과\n",
    "pred = linear(x)\n",
    "loss = loss_function(pred, y)\n",
    "\n",
    "print('Loss after Step BackPropagation ', loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
